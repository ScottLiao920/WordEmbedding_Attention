{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chang.liao/anaconda3/envs/venv/lib/python3.7/site-packages/smart_open/ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import nltk\n",
    "import time\n",
    "from nltk.corpus import gutenberg\n",
    "import gensim\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all sentences in Project Gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sents = []\n",
    "# for file in gutenberg.fileids():\n",
    "#     for sent in gutenberg.sents(file):\n",
    "#         sents.append(sent)\n",
    "# len(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a word2vec model using gensim for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = gensim.models.Word2Vec(sents, size=100, window=5, min_count=1, workers=4)\n",
    "# model.save('word2vec_gensim.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Vocabulary for all the words in Project Gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = []\n",
    "# for file in gutenberg.fileids():\n",
    "#     for word in gutenberg.words(file):\n",
    "#         words.append(word)\n",
    "# # words = list(set(words))\n",
    "# len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fd = nltk.FreqDist(words)\n",
    "# vocab = sorted(fd, key=fd.get, reverse=True)\n",
    "# vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('vocab', 'wb') as f:\n",
    "#     for i in range(len(vocab)):\n",
    "#         f.write('{} {}\\n'.format(vocab[i], i).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('vocab.json', 'w') as f:\n",
    "#     json.dump(vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab.json', 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "                'vocab_size': len(vocab),\n",
    "                'window_size': 5,\n",
    "                'num_epochs': 3,\n",
    "                'embedding_dim': 50,\n",
    "                'batch_size': 512,\n",
    "                'num_heads': 12,\n",
    "                'dim_head': 128,\n",
    "                'learning_rate': 2e-3\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vocab_size': 51156, 'window_size': 5, 'num_epochs': 3, 'embedding_dim': 50, 'batch_size': 512, 'num_heads': 12, 'dim_head': 128, 'learning_rate': 0.002}\n",
      "\n",
      "98552 sentences fetched.\n",
      "\n",
      "51156 unique words found in corpus\n",
      "['\"*', 'The', 'saying', 'become', 'proverbial', 'in']\n",
      "['\"*', 'The', 'saying', 'become', 'proverbial', 'in', 'the']\n",
      "['\"*', 'The', 'saying', 'become', 'proverbial', 'in', 'the', 'village']\n",
      "['\"*', 'The', 'saying', 'become', 'proverbial', 'in', 'the', 'village', '.']\n",
      "['\"*', 'The', 'saying', 'become', 'proverbial', 'in', 'the', 'village', '.']\n",
      "['\"*', 'The', 'saying', 'become', 'proverbial', 'in', 'the', 'village', '.']\n",
      "['\"*']\n",
      "['\"*', 'Each', 'who', 'answers', '\"', 'A']\n",
      "['\"*', 'Each', 'who', 'answers', '\"', 'A', 'Talbotite']\n",
      "['\"*', 'Each', 'who', 'answers', '\"', 'A', 'Talbotite', ',\"']\n",
      "['\"*', 'Each', 'who', 'answers', '\"', 'A', 'Talbotite', ',\"', 'Rory']\n",
      "['\"*', 'Each', 'who', 'answers', '\"', 'A', 'Talbotite', ',\"', 'Rory', 'shakes']\n",
      "['\"*', 'Each', 'who', 'answers', '\"', 'A', 'Talbotite', ',\"', 'Rory', 'shakes', 'by']\n",
      "['\"*']\n",
      "['\"*']\n",
      "['\\'\".']\n",
      "['\"*']\n",
      "['nd', 'desart', 'ways', 'with', '?', 'oeril', 'gone', 'All', '?', 'might', ',?']\n",
      "['desart', 'ways', 'with', '?', 'oeril', 'gone', 'All', '?', 'might', ',?']\n",
      "['ways', 'with', '?', 'oeril', 'gone', 'All', '?', 'might', ',?']\n",
      "['with', '?', 'oeril', 'gone', 'All', '?', 'might', ',?']\n",
      "['?', 'oeril', 'gone', 'All', '?', 'might', ',?']\n",
      "['oeril', 'gone', 'All', '?', 'might', ',?']\n",
      "2621762 pairs found for training\n"
     ]
    }
   ],
   "source": [
    "CBoW_model = scripts.pytorch_model('CBoW', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vocab_size': 51156, 'window_size': 5, 'num_epochs': 3, 'embedding_dim': 50, 'batch_size': 512, 'num_heads': 12, 'dim_head': 128, 'learning_rate': 0.002}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d59c2aba5bfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMSE_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MSE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/WordEmbedding_Attention/scripts.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mode, settings)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;31m# create model object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'MSE'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw2v_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlossfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/WordEmbedding_Attention/scripts.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, settings)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mw2v_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vocab_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "MSE_model = scripts.pytorch_model('MSE', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
